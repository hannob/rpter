#!/usr/bin/python3

import json
import os
import email
import gzip
import zipfile
import io
import argparse
import shutil
import datetime
import dateutil.tz

import xmltodict

count = {}

fcount = {}
tcount = {}

failmsg = ""
warnmsg = ""


def ts2local(ts):
    ts = int(ts)
    dt = datetime.datetime.utcfromtimestamp(ts)
    dt = dt.replace(tzinfo=dateutil.tz.tzutc())
    dt = dt.astimezone(dateutil.tz.tzlocal())
    return dt


def xadd(type, dfrom, org, n=1):
    if not type in fcount:
        fcount[type] = {}
    if not dfrom in fcount[type]:
        fcount[type][dfrom] = 0

    fcount[type][dfrom] += n

    if not type in tcount:
        tcount[type] = {}
    if not org in tcount[type]:
        tcount[type][org] = 0

    tcount[type][org] += n

    if not type in count:
        count[type] = 0
    count[type] += n


def tlsrptparse(indata):
    j = json.loads(indata)
    for p in j["policies"]:
        if p["summary"]["total-successful-session-count"] > 0:
            xadd(
                "tlsrpt_good",
                p["policy"]["policy-domain"],
                j["organization-name"],
                p["summary"]["total-successful-session-count"],
            )
        if p["summary"]["total-failure-session-count"] > 0:
            xadd(
                "tlsrpt_good",
                p["policy"]["policy-domain"],
                j["organization-name"],
                p["summary"]["total-failure-session-count"],
            )


def dmarc(indata):
    global failmsg
    j = xmltodict.parse(indata)
    if "record" not in j["feedback"]:
        return
    recs = j["feedback"]["record"]
    if isinstance(recs, dict):
        recs = [recs]

    org = j["feedback"]["report_metadata"]["org_name"]
    begin = ts2local(j["feedback"]["report_metadata"]["date_range"]["begin"])
    end = ts2local(j["feedback"]["report_metadata"]["date_range"]["end"])

    for r in recs:
        rows = r["row"]

        if isinstance(rows, dict):
            rows = [rows]

        for row in rows:
            pol = row["policy_evaluated"]
            if pol["dkim"] == "pass":
                xadd("dkim_good", r["identifiers"]["header_from"], org)
            else:
                failmsg += f"DKIM did not pass ({pol['dkim']}) from {org}\n"
                failmsg += f"Timeframe {begin} - {end}\n{r}\n\n"
                xadd("dkim_bad", r["identifiers"]["header_from"], org)
            if pol["spf"] == "pass":
                xadd("spf_good", r["identifiers"]["header_from"], org)
            else:
                failmsg += f"SPF did not pass ({pol['spf']}) from {org}\n"
                failmsg += f"Timeframe {begin} - {end}\n{r}\n\n"
                xadd("spf_bad", r["identifiers"]["header_from"], org)


def parser(filename, indata):
    global warnmsg
    if filename.endswith(".json"):
        # this is tls rpt
        tlsrptparse(indata)

    if filename.endswith(".xml"):
        # this is dmarc
        try:
            dmarc(indata)
        except KeyError as e:
            warnmsg += f"Incorrect reporting format in {filename}, key {str(e)}\n"


ap = argparse.ArgumentParser()
ap.add_argument("dirs", nargs="*", help="Path to maildirs to check")
ap.add_argument("-v", "--verbose", action="store_true", help="show also good results")
ap.add_argument("-a,", "--archive", help="Dir to store archived versions")
args = ap.parse_args()

if args.archive:
    now = datetime.datetime.now()
    now = now.replace(tzinfo=dateutil.tz.tzlocal())
    now = now.isoformat(timespec="minutes")
    nowdir = f"{args.archive}/{now}"

for mdir in args.dirs:
    for fmail in os.listdir(mdir):
        if fmail.startswith("."):
            # skip hidden files
            continue
        with open(mdir + fmail, "rb") as f:
            e = email.message_from_binary_file(f)
            dparts = 0
            for part in e.walk():
                ct = part.get_content_type()
                fn = part.get_filename()
                if not isinstance(fn, str):
                    continue
                if fn.endswith(".gz"):
                    if fn.endswith(".gz"):
                        fn = fn[0:-3]
                    data = gzip.decompress(part.get_payload(decode=True))
                    dparts += 1
                    parser(fn, data)

                if ct == "application/zip":
                    bdata = part.get_payload(decode=True)
                    ifo = io.BytesIO(bdata)
                    with zipfile.ZipFile(ifo) as fzip:
                        for x in fzip.namelist():
                            data = fzip.read(x)
                            dparts += 1
                            parser(x, data)
            if dparts == 0:
                warnmsg += f"WARNING: No data found in {fmail}\n"
            if dparts > 1:
                warnmsg += f"WARNING: {dparts} files found, expected 1\n"
        if args.archive:
            if not os.path.isdir(nowdir):
                os.mkdir(nowdir)
            shutil.move(mdir + fmail, nowdir)

if count != {}:
    print("All:")
    print(json.dumps(dict(sorted(count.items())), indent=2))
    print("")
    print("Grouped by from domain:")
    print(json.dumps(dict(sorted(fcount.items())), indent=2))
    print("")
    print("Grouped by reporting org:")
    print(json.dumps(dict(sorted(tcount.items())), indent=2))
    print("")
    print(warnmsg)
    print("")
    print(failmsg)
